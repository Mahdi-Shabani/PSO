# 📝 تسک شماره دو – استفاده از PSO برای انتخاب ویژگی در یادگیری ماشین (Iris Dataset)

## 🎯 هدف
در این بخش، الگوریتم **بهینه‌سازی ازدحام ذرات (PSO)** را روی یک مسئله واقعی‌تر در زمینه **یادگیری ماشین (Machine Learning)** تست می‌کنیم.  

ایده:  
به جای بهینه‌سازی یک تابع ساده ریاضی (مثل مرحله قبل)، این بار از PSO استفاده می‌کنیم تا **بهترین زیرمجموعه از ویژگی‌ها (Feature Subset)** در دیتاست **Iris** انتخاب شود.  

---

## 📌 مسئله انتخاب ویژگی
- دیتاست Iris شامل ۴ ویژگی (Feature) و ۳ کلاس مختلف گل است.  
- هدف: انتخاب بهترین زیرمجموعه از این ویژگی‌ها برای آموزش یک مدل ساده (Decision Tree).  
- تابع هدف به این شکل تعریف شده:  

```math
\text{Objective} = 1 - Accuracy
```
چون الگوریتم PSO یک مینیمم‌کننده است و ما می‌خواهیم دقت (Accuracy) را ماکزیمم کنیم.

⚙️ نحوه عملکرد
هر ذره در PSO یک بردار دودویی از ویژگی‌هاست:
مثال: [1, 0, 1, 1] یعنی ویژگی دوم حذف و بقیه انتخاب شوند.
تابع هدف: برای هر ذره یک مدل DecisionTreeClassifier آموزش داده و دقت آن روی داده تست محاسبه می‌شود.
PSO با به‌روزرسانی موقعیت‌ها و سرعت‌ها سعی می‌کند بهترین subset را پیدا کند.

---

## 📊 روند کار فایل‌ها
1. **dataset_loader.py** → بارگذاری دیتاست Iris و تقسیم به train/test  
2. **objective_function.py** → تعریف تابع هدف بر اساس دقت مدل Decision Tree  
3. **particle.py** → تعریف موقعیت و رفتار ذره‌ها (برای انتخاب ویژگی)  
4. **pso.py** → اجرای الگوریتم PSO، مدیریت همه ذره‌ها، پیدا کردن gBest  
5. **main.py** → تنظیم پارامترها، اجرای PSO و نمایش نتیجه  

---

## ▶️ نحوه اجرا
از مسیر پروژه دستور زیر را اجرا کنید:

```bash
cd PSO_ML_Project
python main.py
```

📊 نمونه خروجی
(به علت تصادفی بودن، هر بار مقدار و انتخاب ویژگی‌ها ممکن است تغییر کند)
```
Iteration 0: gBest = 0.355
Iteration 10: gBest = 0.089
Iteration 20: gBest = 0.044
Iteration 30: gBest = 0.022
Iteration 40: gBest = 0.022
```
✅ نتیجه نهایی:
```
بهترین subset ویژگی‌ها = [ True False  True  True]
هزینه (1 - دقت مدل) = 0.022
دقت مدل = 0.978
```
به این معنا که الگوریتم یاد گرفته با حذف ویژگی دوم و استفاده از سه ویژگی دیگر، همچنان می‌توان به دقت نزدیک به ۹۸٪ رسید.


در تسک شماره دو، الگوریتم PSO را روی یک دیتای واقعی (Iris) به کار بردم تا بهترین ترکیب از ویژگی‌ها انتخاب شود.
هر ذره نماینده یک subset از ویژگی‌ها بود. تابع هدف بر اساس دقت یک مدل Decision Tree روی داده تست تعریف شد.
در نهایت PSO توانست زیرمجموعه‌ای از ویژگی‌ها را پیدا کند که دقت بالایی به مدل بدهد، در حالی که تعداد ویژگی‌ها کمتر شده است. این نشان می‌دهد PSO می‌تواند به عنوان ابزاری برای Feature Selection در حوزه یادگیری ماشین استفاده شود.
